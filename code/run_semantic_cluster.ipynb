{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from collect_data import *\n",
    "import torch\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 395999  =      0.000 ...   395.999 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/spect-to-meg/code/collect_data.py:47: RuntimeWarning: The unit for channel(s) MISC 001, MISC 002, MISC 003, MISC 004, MISC 005, MISC 006, MISC 007, MISC 008, MISC 009, MISC 010, MISC 011, MISC 012, MISC 013, MISC 014, MISC 015, MISC 016, MISC 017, MISC 018, MISC 019, MISC 020, MISC 021, MISC 022, MISC 023, MISC 024, MISC 025, MISC 026, MISC 027, MISC 028, MISC 029, MISC 030, MISC 031, MISC 032 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 6601 samples (6.601 s)\n",
      "\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    }
   ],
   "source": [
    "raw = get_bids_raw(meg_path, patient[0], session[0], '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 18 columns\n",
      "180 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 180 events and 3201 original time points ...\n",
      "0 bad epochs dropped\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    }
   ],
   "source": [
    "get_epochs = get_epochs(raw, task.get(\"lw1\"), float(lw1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH_SHAPE:  (180, 208, 3201)\n"
     ]
    }
   ],
   "source": [
    "print('EPOCH_SHAPE: ', get_epochs.get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lw1', 'cable_spool_fort', 'easy_money', 'the_black_willow']\n"
     ]
    }
   ],
   "source": [
    "wav_list_without_numb = list(task.keys())\n",
    "print(wav_list_without_numb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = os.path.join(meg_path, 'collect_data/audio')\n",
    "audio_list = os.listdir(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8561\n"
     ]
    }
   ],
   "source": [
    "# CLIP necessit√† di immagini con 3 canali RGB ? \n",
    "colormap = cm.get_cmap('viridis')\n",
    "audio_data = []\n",
    "audio_shape = []\n",
    "for file_name in audio_list:\n",
    "    file_path = os.path.join(audio_path, file_name)\n",
    "    tensor = torch.load(file_path)\n",
    "    audio_shape.append(tensor.shape[0])\n",
    "    normalized_spectrogram = (tensor - tensor.min()) / (tensor.max() - tensor.min())\n",
    "    rgba_image = colormap(normalized_spectrogram.numpy())\n",
    "    rgb_image = torch.tensor(rgba_image[:, :, :, :3]).permute(0, 3, 1, 2)\n",
    "    audio_data.append(rgb_image)\n",
    "audio_tensor = list(torch.cat(audio_data, dim=0))\n",
    "print(len(audio_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_list = []\n",
    "words_shape = []\n",
    "for task_name, task_value in task.items():\n",
    "    print(f\"TASK_NAME: {task_name}, TASK_VALUE: {task_value}\")\n",
    "    pieces = []\n",
    "    if task_name == 'lw1':\n",
    "        pieces = lw1\n",
    "    elif task_name == 'cable_spool_fort':\n",
    "        pieces = cable_spool_fort\n",
    "    elif task_name == 'easy_money':\n",
    "        pieces = easy_money\n",
    "    elif task_name == 'the_black_willow':\n",
    "        pieces = the_black_willow\n",
    "    for piece in pieces:\n",
    "        print(f\"PIECE_OF_TASK: {piece}\")\n",
    "        raw = get_bids_raw(meg_path, patient[0], session[0], str(int(task_value)))\n",
    "        meta = list()\n",
    "        for annot in raw.annotations:\n",
    "            d = eval(annot.pop(\"description\"))\n",
    "            for k, v in annot.items():\n",
    "                assert k not in d.keys()\n",
    "                d[k] = v\n",
    "            meta.append(d)\n",
    "        meta = pd.DataFrame(meta)\n",
    "        meta[\"intercept\"] = 1.0\n",
    "        meta=meta[(meta[\"kind\"]==\"word\") & (meta[\"story_uid\"]==task_value) & \n",
    "                    (meta[\"sound_id\"]==float(piece))]  \n",
    "        words = meta[\"word\"].to_numpy()\n",
    "        print('WORDS_SHAPE: ', words.shape)\n",
    "        words_list.append(words)\n",
    "        words_shape.append(words.shape[0])\n",
    "\n",
    "wordres_list = [item for array in words_list for item in array]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8561\n"
     ]
    }
   ],
   "source": [
    "save_words_path = os.path.join(meg_path, 'collect_data/words_audio_encoding.npy')\n",
    "# np.save(save_words_path, wordres_list)\n",
    "loaded_list = list(np.load(save_words_path, allow_pickle=True))\n",
    "print(len(loaded_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramTextDataset(Dataset):\n",
    "    def __init__(self, spectrograms, text_labels):\n",
    "        self.spectrograms = spectrograms\n",
    "        self.text_labels = text_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.spectrograms)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spectrogram = self.spectrograms[idx]\n",
    "        text = self.text_labels[idx]\n",
    "        return spectrogram, text\n",
    "\n",
    "# Tokenizer and model initialization\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "\n",
    "dataset = SpectrogramTextDataset(audio_tensor, loaded_list)\n",
    "dataloader = DataLoader(dataset, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-meg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
